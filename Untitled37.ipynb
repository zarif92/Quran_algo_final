{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea460b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY Optimized Linear Regression MSE: 0.0\n",
      "Optimal Prime Weights: {8: 0.01, 11: 0.01, 12: 10.0, 14: 0.01, 15: 0.01, 16: 0.01, 22: 0.01, 23: 10.0, 26: 10.0, 27: 0.01, 28: 10.0, 29: 10.0, 30: 0.01, 31: 0.01, 32: 0.01, 33: 10.0, 34: 10.0, 35: 10.0, 36: 10.0, 37: 10.0, 38: 0.01, 39: 10.0, 40: 0.01, 41: 0.01, 42: 0.01, 43: 10.0, 44: 0.01, 45: 0.01, 46: 0.01}\n",
      "Optimal Feature Weights: [10. 10. 10. 10. 10.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META Optimized Linear Regression MSE: 3.877409121342317e-28\n",
      "Optimal Prime Weights: {8: 0.01, 11: 0.01, 12: 10.0, 14: 0.01, 15: 0.01, 16: 0.01, 22: 0.01, 23: 10.0, 26: 10.0, 27: 0.01, 28: 10.0, 29: 10.0, 30: 0.01, 31: 0.01, 32: 0.01, 33: 10.0, 34: 10.0, 35: 10.0, 36: 10.0, 37: 10.0, 38: 0.01, 39: 10.0, 40: 0.01, 41: 0.01, 42: 0.01, 43: 10.0, 44: 0.01, 45: 0.01, 46: 0.01}\n",
      "Optimal Feature Weights: [10.   10.   10.   10.    0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGL Optimized Linear Regression MSE: 0.0\n",
      "Optimal Prime Weights: {8: 0.01, 11: 0.01, 12: 10.0, 14: 0.01, 15: 0.01, 16: 0.01, 22: 0.01, 23: 0.01, 26: 10.0, 27: 0.01, 28: 10.0, 29: 10.0, 30: 0.01, 31: 0.01, 32: 10.0, 33: 10.0, 34: 10.0, 35: 10.0, 36: 10.0, 37: 10.0, 38: 0.01, 39: 10.0, 40: 0.01, 41: 10.0, 42: 0.01, 43: 10.0, 44: 0.01, 45: 10.0, 46: 10.0}\n",
      "Optimal Feature Weights: [10. 10. 10. 10. 10.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT Optimized Linear Regression MSE: 1.2278462217584005e-27\n",
      "Optimal Prime Weights: {8: 0.01, 11: 0.01, 12: 10.0, 14: 0.01, 15: 0.01, 16: 0.01, 22: 0.01, 23: 10.0, 26: 10.0, 27: 0.01, 28: 0.01, 29: 10.0, 30: 0.01, 31: 0.01, 32: 0.01, 33: 10.0, 34: 10.0, 35: 10.0, 36: 0.01, 37: 10.0, 38: 0.01, 39: 10.0, 40: 10.0, 41: 0.01, 42: 0.01, 43: 10.0, 44: 0.01, 45: 10.0, 46: 0.01}\n",
      "Optimal Feature Weights: [10. 10. 10. 10. 10.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA Optimized Linear Regression MSE: 8.683780844672898e-29\n",
      "Optimal Prime Weights: {8: 0.01, 11: 0.01, 12: 10.0, 14: 0.01, 15: 0.01, 16: 0.01, 22: 0.01, 23: 10.0, 26: 10.0, 27: 0.01, 28: 10.0, 29: 10.0, 30: 0.01, 31: 0.01, 32: 10.0, 33: 10.0, 34: 10.0, 35: 10.0, 36: 10.0, 37: 0.01, 38: 0.01, 39: 10.0, 40: 10.0, 41: 10.0, 42: 0.01, 43: 10.0, 44: 0.01, 45: 10.0, 46: 0.01}\n",
      "Optimal Feature Weights: [10. 10. 10. 10. 10.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL Optimized Linear Regression MSE: 0.0\n",
      "Optimal Prime Weights: {8: 10.0, 11: 0.01, 12: 0.01, 14: 10.0, 15: 0.01, 16: 0.01, 22: 0.01, 23: 10.0, 26: 0.01, 27: 10.0, 28: 10.0, 29: 0.01, 30: 0.01, 31: 10.0, 32: 0.01, 33: 10.0, 34: 0.01, 35: 10.0, 36: 0.01, 37: 10.0, 38: 0.01, 39: 10.0, 40: 10.0, 41: 0.01, 42: 10.0, 43: 0.01, 44: 10.0, 45: 0.01, 46: 10.0}\n",
      "Optimal Feature Weights: [10.   10.   10.   10.    0.01]\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the CSV file with prime factors and ranks\n",
    "file_path = '/Users/mac/Desktop/mahdi_313.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to assign weights based on prime numbers\n",
    "def assign_weights(rankings, prime_weights, default_weight=1.0):\n",
    "    return np.array([prime_weights.get(rank, default_weight) for rank in rankings])\n",
    "\n",
    "# Define the optimizer function based on the ranking of abjad\n",
    "def prime_weighted_objective_function(weights, features, rankings, prime_weights, default_weight):\n",
    "    adjusted_features = features * weights\n",
    "    assigned_weights = assign_weights(rankings, prime_weights, default_weight)\n",
    "    scores = np.sum(adjusted_features * assigned_weights[:, None], axis=1)\n",
    "    return -np.mean(scores)  # We minimize negative score to maximize positive score\n",
    "\n",
    "# Function to optimize prime weights and feature weights\n",
    "def optimize_prime_weights_and_features(X_train, y_train, rankings, initial_prime_weights, initial_feature_weights, default_weight=1.0):\n",
    "    def objective(combined_weights):\n",
    "        feature_weights = combined_weights[:X_train.shape[1]]\n",
    "        prime_weights = combined_weights[X_train.shape[1]:]\n",
    "        prime_weights_dict = {rank: weight for rank, weight in zip(np.unique(rankings), prime_weights)}\n",
    "        return prime_weighted_objective_function(feature_weights, X_train, rankings, prime_weights_dict, default_weight)\n",
    "    \n",
    "    # Initial combined weights\n",
    "    initial_combined_weights = np.concatenate([initial_feature_weights, initial_prime_weights])\n",
    "\n",
    "    # Bounds for feature weights and prime weights\n",
    "    bounds = [(0.01, 10)] * len(initial_combined_weights)\n",
    "\n",
    "    result = minimize(objective, initial_combined_weights, method='L-BFGS-B', bounds=bounds)\n",
    "    optimal_combined_weights = result.x\n",
    "\n",
    "    optimal_feature_weights = optimal_combined_weights[:X_train.shape[1]]\n",
    "    optimal_prime_weights = optimal_combined_weights[X_train.shape[1]:]\n",
    "    \n",
    "    prime_weights_dict = {rank: weight for rank, weight in zip(np.unique(rankings), optimal_prime_weights)}\n",
    "    return optimal_feature_weights, prime_weights_dict\n",
    "\n",
    "# Function to run the optimization and calculate MSE for a given stock ticker\n",
    "def run_simulation(stock_ticker):\n",
    "    # Fetch historical data\n",
    "    data = yf.download(stock_ticker, start='2023-06-10', end='2024-06-10')\n",
    "\n",
    "    if data.empty:\n",
    "        print(f\"No data found for {stock_ticker}\")\n",
    "        return\n",
    "\n",
    "    # Feature selection\n",
    "    features = data[['Open', 'High', 'Low', 'Close', 'Volume']].values\n",
    "    target = data['Close'].values\n",
    "\n",
    "    # Add the ranking feature from the CSV\n",
    "    rankings = df['Rank'].values[:len(features)]\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initial weights for optimization\n",
    "    initial_feature_weights = np.ones(X_train.shape[1])\n",
    "    initial_prime_weights = np.ones(len(np.unique(rankings)))  # Initial weights for each unique prime rank\n",
    "\n",
    "    # Optimize prime weights and feature weights\n",
    "    optimal_feature_weights, optimal_prime_weights = optimize_prime_weights_and_features(\n",
    "        X_train, y_train, rankings[:len(X_train)], initial_prime_weights, initial_feature_weights\n",
    "    )\n",
    "\n",
    "    # Adjust features based on the optimized weights\n",
    "    X_train_opt = X_train * optimal_feature_weights\n",
    "    X_test_opt = X_test * optimal_feature_weights\n",
    "\n",
    "    # Train the Optimized Linear Regression model\n",
    "    model_lr = LinearRegression()\n",
    "    model_lr.fit(X_train_opt, y_train)\n",
    "    y_pred_lr = model_lr.predict(X_test_opt)\n",
    "    mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "\n",
    "    # Print the MSE of the new model\n",
    "    print(f'{stock_ticker} Optimized Linear Regression MSE: {mse_lr}')\n",
    "    print(f'Optimal Prime Weights: {optimal_prime_weights}')\n",
    "    print(f'Optimal Feature Weights: {optimal_feature_weights}')\n",
    "\n",
    "# List of selected stocks\n",
    "selected_stocks = ['SPY', 'META', 'GOOGL', 'MSFT', 'NVDA', 'AAPL']\n",
    "\n",
    "# Run the simulation for selected stocks\n",
    "for stock in selected_stocks:\n",
    "    run_simulation(stock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c487852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
